{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-timers (\"stuff that needs to be done once\")\n",
    "\n",
    "This section will define all functions and parameters, needed for the pipeline. Also, if experiments were necessary, they were laid out in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"./camera_cal/calibration*.jpg\")\n",
    "\n",
    "# array ti store object and images points\n",
    "# top left (0,0,0), bottom right (7,5,0)\n",
    "\n",
    "objpoints = [] # 3d points in real world\n",
    "imgpoints = [] # 2D points in image plane\n",
    "\n",
    "# prepare oiunts, like (0,0,0), (1,0,0), (2,0,0), ... (7,5,0)\n",
    "n_x = 9\n",
    "n_y = 6\n",
    "objp = np.zeros((n_x*n_y,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:n_x, 0:n_y].T.reshape(-1, 2) # x, y coordinates\n",
    "\n",
    "for img_name in images:\n",
    "    # Load image\n",
    "    img = mpimg.imread(img_name)\n",
    "    \n",
    "    # Convert to grayscale image\n",
    "    grayscale_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # find chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(grayscale_image, (n_x, n_y), None)\n",
    "\n",
    "    # if corners are found, add object points, image points\n",
    "    if ret is True:\n",
    "        print(\"appending points for image {}...\".format(img_name))\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp) # everytime the same, cause it the \"real\" chessboard\n",
    "\n",
    "        # draw n display\n",
    "        img = cv2.drawChessboardCorners(img, (8,6), corners, ret)\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        print(\"there is an issue with image {}, right number of corners cannot be found\".format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"./camera_cal/calibration2.jpg\"\n",
    "test_img = mpimg.imread(img_name)\n",
    "\n",
    "# objpoints is our original array of all real points and imgpoints now holds the result of all calibration images\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, test_img[:,:,2].shape[::-1], None, None)\n",
    "print(\"camera calibrated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shorter for future use\n",
    "def ud(img, my_mtx = mtx, my_dist = dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot comparision\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "plt.subplot(1, 2, 1) #one row, two col, first plot\n",
    "img_name = \"./camera_cal/calibration2.jpg\"\n",
    "test_img = mpimg.imread(img_name)\n",
    "plt.imshow(test_img)\n",
    "plt.title(\"original image\")\n",
    "\n",
    "plt.subplot(1, 2, 2) #one row, two col, first plot\n",
    "test_img_udst = ud(test_img)\n",
    "plt.imshow(test_img_udst)\n",
    "plt.title(\"undistorted image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "\n",
    "image = mpimg.imread('test_images/test5.jpg')\n",
    "\n",
    "def img_to_0_255(img):\n",
    "    img *= (255.0/img.max())\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "# Edit this function to create your own pipeline.\n",
    "def threshold(img, s_thresh=(170, 255), sx_thresh=(20, 100), l_thresh=(225, 255), video_mode=True):\n",
    "    global img_dbg\n",
    "    global s_channel\n",
    "    global s_binary\n",
    "    global yellow_mask\n",
    "    global hsv\n",
    "    global l_binary\n",
    "    \n",
    "    if isinstance(img[0,0,0], np.float32):\n",
    "        img = img_to_0_255(np.copy(img))\n",
    "    \n",
    "    \n",
    "    img_dbg = img\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # YELLOW lines\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.uint8)\n",
    "    #yellow_hsv_low  = np.array([ 10, 100, 0])\n",
    "    #yellow_hsv_high = np.array([ 50, 255, 255])\n",
    "    yellow_hsv_low  = np.array([ 0, 100, 100])\n",
    "    yellow_hsv_high = np.array([ 50, 255, 255])\n",
    "    yellow_mask = cv2.inRange(hsv, yellow_hsv_low, yellow_hsv_high)\n",
    "    \n",
    "    # WHITE lines\n",
    "    # best using L channel, HSV space didnt yield good results\n",
    "    white_hsv_low  = np.array([  20,   0,   180])\n",
    "    white_hsv_high = np.array([ 255,  80, 255])\n",
    "    white_mask = cv2.inRange(hsv, white_hsv_low, white_hsv_high)\n",
    "    \n",
    "    # Threshold color channel S\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    #color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    \n",
    "    # Threshold color channel L\n",
    "    # this is great for finding the white line\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_channel = np.uint8(255*l_channel/np.max(l_channel))\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    #color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, l_binary)) * 255\n",
    "    combined_color_binary = np.zeros_like(yellow_mask)\n",
    "    combined_color_binary[(yellow_mask > 0) | (l_binary > 0)] = 1\n",
    "    \n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(combined_color_binary, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    #combine\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(sxbinary == 1)] = 1\n",
    "    \n",
    "    if not video_mode:\n",
    "        fig = plt.figure(figsize=(15, 11))\n",
    "        plt.subplot(3, 2, 1)\n",
    "        plt.imshow(white_mask, cmap=\"gray\")\n",
    "        plt.title(\"white_mask\")\n",
    "        plt.subplot(3, 2, 2)\n",
    "        plt.imshow(yellow_mask, cmap=\"gray\")\n",
    "        plt.title(\"yellow_mask\")\n",
    "        plt.subplot(3, 2, 3)\n",
    "        plt.imshow(s_binary, cmap=\"gray\")\n",
    "        plt.title(\"s_binary\")\n",
    "        plt.subplot(3, 2, 4)\n",
    "        plt.imshow(l_binary, cmap=\"gray\")\n",
    "        plt.title(\"l_binary\")\n",
    "        plt.subplot(3, 2, 5)\n",
    "        plt.imshow(sxbinary, cmap=\"gray\")\n",
    "        plt.title(\"sxbinary\")\n",
    "        plt.subplot(3, 2, 6)\n",
    "        plt.imshow(combined_binary, cmap=\"gray\")\n",
    "        plt.title(\"Final\")\n",
    "        plt.show()\n",
    "        \n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"test_images/test4.jpg\")\n",
    "undistorted = ud(img)\n",
    "warped = warp(undistorted)\n",
    "\n",
    "result = threshold(warped, s_thresh=(170, 255), sx_thresh=(50, 225), l_thresh=(225, 255), video_mode=False)\n",
    "plt.imshow(result, cmap=\"gray\")\n",
    "plt.title(\"RESULT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    img = mpimg.imread(\"stress_images/stress2.png\")\n",
    "    img = mpimg.imread(\"test_images/straight_lines1.jpg\")\n",
    "    undistorted = ud(img)\n",
    "    warped = warp(undistorted)\n",
    "\n",
    "    result = threshold(warped, s_thresh=(170, 255), sx_thresh=(50, 225), l_thresh=(225, 255), video_mode=False)\n",
    "    plt.imshow(result, cmap=\"gray\")\n",
    "    plt.title(\"RESULT\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def warp(img, \n",
    "         src = [[-320, 720], [510, 460], [770, 460], [1600, 720]], \n",
    "         dst = [[0, 720], [0, 0], [1280, 0], [1280, 720]],\n",
    "         invert=False):\n",
    "    \n",
    "\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    src = np.float32(src)\n",
    "\n",
    "    dst = np.float32(dst)\n",
    "\n",
    "    # compute the transformation\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # compute the inverse to reverse the transformation\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    #  ---> X\n",
    "    #  | 1....2\n",
    "    # \\/ ......\n",
    "    # y  0....3\n",
    "    #target_dim_x = int(dst[2][0] - dst[0][0])\n",
    "    #target_dim_y = int(dst[0][1] - dst[1][1])\n",
    "    #warped = warped[0:target_dim_y, 0:target_dim_x] # Crop from x, y, w, h -> 100, 200, 300, 400\n",
    "\n",
    "    if invert:\n",
    "        # get warped image\n",
    "        return cv2.warpPerspective(img, Minv, img_size, flags=cv2.INTER_LINEAR, # INTER_CUBIC\n",
    "                                   borderMode=cv2.BORDER_CONSTANT, borderValue = [0, 0, 0, 0])\n",
    "    else:\n",
    "        return cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR, # INTER_CUBIC\n",
    "                                   borderMode=cv2.BORDER_CONSTANT, borderValue = [0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell was used to manually evaluate different warping and selection regions. As it turned out, selecting the complete part of the lower image is necessary to catch lanes when the car is close to the edge of the lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Read and dispaly the original image\n",
    "img = mpimg.imread(\"test_images/straight_lines1.jpg\")\n",
    "im_height, im_width, im_depth = img.shape\n",
    "distance_x_close = -320  # distance between border of image and polygon\n",
    "distance_x_far = 510\n",
    "px_y_close = im_height\n",
    "px_y_far = 460\n",
    "\n",
    "# source rectangle\n",
    "x_plot = [distance_x_close, distance_x_far, im_width - distance_x_far, im_width - distance_x_close]\n",
    "x_plot.append(x_plot[0])\n",
    "y_plot = [px_y_close, px_y_far, px_y_far, px_y_close]\n",
    "y_plot.append(y_plot[0])\n",
    "src = []\n",
    "for i, (x, y) in enumerate(zip(x_plot, y_plot)):\n",
    "    if i > 3:\n",
    "        # not used for warping, just for visualization\n",
    "        break\n",
    "    src.append([x, y])\n",
    "\n",
    "dst_size_image = distance_x_far\n",
    "#x_dst = [distance_x_close, distance_x_close, im_width - distance_x_close, im_width - distance_x_close]\n",
    "x_dst = [0, 0, im_width, im_width]\n",
    "y_dst = [im_height, 0, 0,  im_height]\n",
    "dst = []\n",
    "for (x, y) in zip(x_dst, y_dst):\n",
    "    dst.append([x, y])\n",
    "\n",
    "images = glob.glob(\"test_images/*.jpg\")\n",
    "for pth in images:\n",
    "    img = mpimg.imread(pth)\n",
    "    f_name = os.path.basename(pth)\n",
    "    result = warp(img, src=src, dst = dst)#, img_shape=[dst_size_image, dst_size_image])\n",
    "    \n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(\"original image ({})\".format(f_name), fontsize=40)\n",
    "    ax1.plot(x_plot, y_plot, linewidth=4, color=\"r\")\n",
    "\n",
    "    ax2.imshow(result, cmap='gray')\n",
    "    ax2.set_title('warped image ({})'.format(f_name), fontsize=40)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sections = 2\n",
    "#histogram = np.sum(warped_thresholded[warped_thresholded.shape[0]//sections:,:], axis=0)\n",
    "#plt.plot(histogram)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        \n",
    "        self.trust = 0 # integer ranging from 0 to 8 to indicate the confidence in the line\n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None    \n",
    "        \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        \n",
    "        #x values for detected line pixels\n",
    "        self.allx = np.array([], dtype=int)  \n",
    "        \n",
    "        #y values for detected line pixels\n",
    "        self.ally = np.array([], dtype=int)  \n",
    "        \n",
    "        # last centroid closest to the car\n",
    "        self.centroid = None\n",
    "        \n",
    "        self.n_frames_for_averaging = 5 # number of iterations for smoothing\n",
    "\n",
    "    def append_fit(self, fit):\n",
    "        if (self.detected and self.trust > 400) or len(self.recent_xfitted) == 0:\n",
    "            self.current_fit = fit\n",
    "            \n",
    "            #trust_to_use = (1 if self.trust < 1 else self.trust)\n",
    "            #self.recent_xfitted.append([fit] * trust_to_use)\n",
    "            self.recent_xfitted.append(fit)\n",
    "            if len(self.recent_xfitted) > self.n_frames_for_averaging: self.recent_xfitted.pop(0) # drop first\n",
    "        #else:\n",
    "        #    print(\"rejected, no trust ({})\".format(self.trust))\n",
    "            \n",
    "    def get_averaged_fit(self):\n",
    "        return np.mean(self.recent_xfitted, axis=0)\n",
    "    \n",
    "class Car():\n",
    "    def __init__(self):\n",
    "        center_px_x = 720 # center of car in the lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(warped, window_width = 50, window_height = 160, margin = 80, video_mode=False):\n",
    "    \"\"\"\n",
    "    :param window_height: Break image into 9 vertical layers since image height is 720\n",
    "    :param margin:  How much to slide left and right for searching, default was 100\n",
    "    \"\"\"\n",
    "    global left_line\n",
    "    global right_line\n",
    "    global window_centroids\n",
    "    global l_sum\n",
    "    global l_center\n",
    "    global r_sum\n",
    "    global r_center\n",
    "    \n",
    "    conv_threshold = 5000\n",
    "    conv_threshold_first = 5000\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "\n",
    "    # just for reference: warped.shape yields [720,1280] => first dim is height (as always)\n",
    "\n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "    l_conv_signal = np.convolve(window,l_sum)\n",
    "    if np.sum(l_conv_signal) < conv_threshold*10 and left_line.centroid is not None:\n",
    "        if not video_mode: print(\"left: using centroid from last frame {}\".format(left_line.centroid))\n",
    "        l_center = left_line.centroid\n",
    "    else:\n",
    "        l_center = np.argmax(l_conv_signal)-window_width/2\n",
    "        left_line.detected = True\n",
    "\n",
    "    r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "    r_conv_signal = np.convolve(window,r_sum)\n",
    "    if np.sum(r_conv_signal) < np.sum(l_conv_signal) * 0.35:\n",
    "        if right_line.centroid is not None: # first time, in front of car\n",
    "            # use the center from last iteration\n",
    "            if not video_mode: print(\"right: using centroid from last frame {}\".format(right_line.centroid))\n",
    "            r_center = right_line.centroid\n",
    "        else:  # no last centroid available\n",
    "            if not video_mode: print(\"right: using centroid based on left line.\")\n",
    "            r_center = l_center + 638\n",
    "    else:\n",
    "        r_center = np.argmax(r_conv_signal)-window_width/2+int(warped.shape[1]/2)\n",
    "        right_line.detected = True\n",
    "        \n",
    "    if not video_mode: print(\"r_conv_signal={}\".format(np.sum(r_conv_signal)))\n",
    "    if not video_mode: print(\"l_conv_signal={}\".format(np.sum(l_conv_signal)))\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    l_last_delta = 0\n",
    "    r_last_delta = 0\n",
    "    n_vertical_slices = int(warped.shape[0]/window_height)\n",
    "    for level in range(1,n_vertical_slices):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        slice_start = int(warped.shape[0]-(level+1)*window_height)\n",
    "        slice_end = int(warped.shape[0]-level*window_height)\n",
    "        if not video_mode:\n",
    "            print(\"slicing from {} to {}.\".format(slice_start, slice_end))\n",
    "\n",
    "        image_slice = warped[slice_start:slice_end,:]  # get image slice\n",
    "        image_layer = np.sum(image_slice, axis=0)      # sum slice in y direction, to only get 1x1280 image\n",
    "\n",
    "        # convole works like this np.convolve([1, 2, 3], [0, 1, 1]) -> array([0, 1, 3, 5, 3])\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(min(max(l_center+offset-margin,0), warped.shape[1]))\n",
    "        l_max_index = int(max(min(l_center+offset+margin,warped.shape[1]), 0))\n",
    "        if l_min_index == l_max_index:\n",
    "            l_min_index = l_max_index - 1\n",
    "        l_conv_signal = conv_signal[l_min_index:l_max_index]\n",
    "        if len(l_conv_signal) > 0:\n",
    "            l_center_new = np.argmax(l_conv_signal)+l_min_index-offset\n",
    "        else:\n",
    "            l_center_new = l_center + 638\n",
    "            \n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(min(max(r_center+offset-margin,0), warped.shape[1]))\n",
    "        r_max_index = int(max(min(r_center+offset+margin,warped.shape[1]), 0))\n",
    "        if r_min_index == r_max_index:\n",
    "            r_min_index = r_max_index - 1\n",
    "        r_conv_signal = conv_signal[r_min_index:r_max_index]\n",
    "        if len(r_conv_signal) > 0:\n",
    "            r_center_new = np.argmax(r_conv_signal)+r_min_index-offset\n",
    "        else:\n",
    "            r_center_new = r_center\n",
    "        \n",
    "        if not video_mode:\n",
    "            print(\"conv_left={}, conv_right={}, level={}\".format(np.sum(l_conv_signal), np.sum(r_conv_signal), level))\n",
    "        if (np.sum(l_conv_signal) < conv_threshold):\n",
    "            l_center = l_center + l_last_delta\n",
    "        else:\n",
    "            left_line.trust = level\n",
    "            l_last_delta = l_center_new - l_center\n",
    "            l_center = l_center_new\n",
    "\n",
    "        if (np.sum(r_conv_signal) < conv_threshold):\n",
    "            r_center = r_center + r_last_delta\n",
    "        else:\n",
    "            r_last_delta = 0 #r_center_new - r_center\n",
    "            r_center = r_center_new\n",
    "            right_line.trust = level\n",
    "\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "        \n",
    "    left_line.centroid = window_centroids[0][0]\n",
    "    right_line.centroid = window_centroids[0][1]\n",
    "\n",
    "    return window_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blend_transparent(face_img, overlay_t_img):\n",
    "    # https://stackoverflow.com/questions/40895785/using-opencv-to-overlay-transparent-image-onto-another-image\n",
    "    # Split out the transparency mask from the colour info\n",
    "    overlay_img = overlay_t_img[:,:,:3] # Grab the BRG planes\n",
    "    overlay_mask = overlay_t_img[:,:,3:]  # And the alpha plane\n",
    "\n",
    "    # Again calculate the inverse mask\n",
    "    background_mask = 255 - overlay_mask\n",
    "\n",
    "    # Turn the masks into three channel, so we can use them as weights\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert the images to floating point in range 0.0 - 1.0\n",
    "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "    # And finally just add them together, and rescale it back to an 8bit integer image    \n",
    "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if everything was calculated, this function is used to transform the image back\n",
    "# and paint the lines on it\n",
    "def fit_lanes_on_image(leftx, lefty, rightx, righty, dx, right_r, left_r,\n",
    "                       birdeye_image, orig_image, ploty, video_mode=False):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    #orig_image = img.copy()\n",
    "    #orig_image = cv2.cvtColor(orig_image, cv2.COLOR_RGBA2RGB)\n",
    "        \n",
    "    birdeye_image = cv2.cvtColor(birdeye_image, cv2.COLOR_RGB2RGBA).copy()\n",
    "\n",
    "    yvals = np.linspace(0, birdeye_image.shape[0] - 1, birdeye_image.shape[0])\n",
    "\n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    left_fit_cr_avg = left_line.get_averaged_fit()\n",
    "    right_fit_cr_avg = right_line.get_averaged_fit()\n",
    "    left_fitx = left_fit_cr_avg[0] * ploty ** 2 + left_fit_cr_avg[1] * ploty + left_fit_cr_avg[2]\n",
    "    #if right_fit_cr_avg[0] < 0.001 or right_fit_cr_avg[0] > -0.001:\n",
    "    #    right_fitx = right_fit_cr_avg[0] * ploty ** 2 + right_fit_cr_avg[1] * ploty + right_fit_cr_avg[2]        \n",
    "    #else:\n",
    "    right_fitx = right_fit_cr_avg[0] * ploty ** 2 + right_fit_cr_avg[1] * ploty + right_fit_cr_avg[2]\n",
    "\n",
    "    # plot the data using cv2\n",
    "    left_line.current_fit = left_fitx\n",
    "    right_line.current_fit = right_fitx\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(birdeye_image).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    pts_l = np.transpose(np.vstack([left_line.current_fit, yvals])).reshape((-1, 1, 2)).astype(np.int32)\n",
    "    pts_r = np.transpose(np.vstack([right_line.current_fit, yvals])).reshape((-1, 1, 2)).astype(np.int32)\n",
    "    pts = np.vstack([pts_l, pts_r[::-1]])\n",
    "    bg_image_copy = birdeye_image.copy()\n",
    "    cv2.fillPoly(bg_image_copy, [pts], color=(0, 255, 0, 255))\n",
    "    alpha = 0.3\n",
    "    cv2.addWeighted(bg_image_copy, alpha, birdeye_image, 1 - alpha, 0, birdeye_image)\n",
    "\n",
    "    # Draw lane markers\n",
    "    cv2.drawContours(birdeye_image, pts_l, -1, (255, 0, 0, 255), thickness=30)\n",
    "    cv2.drawContours(birdeye_image, pts_r, -1, (0, 0, 255, 255), thickness=30)\n",
    "    if not video_mode:\n",
    "        birdeye_image_rgb = cv2.cvtColor(birdeye_image,cv2.COLOR_RGBA2RGB)\n",
    "        plt.imshow(birdeye_image_rgb)\n",
    "        plt.title(\"enhanced bird eye\")\n",
    "        plt.show()\n",
    "\n",
    "    # warp back the image\n",
    "    bg_image_warped_back = warp(birdeye_image, invert=True)\n",
    "    if not video_mode:\n",
    "        plt.imshow(bg_image_warped_back)\n",
    "        plt.title(\"enhanced bird eye warped back\")\n",
    "        plt.show()\n",
    "    if not video_mode:\n",
    "        plt.imshow(orig_image)\n",
    "        plt.title(\"orig_image\")\n",
    "        plt.show()\n",
    "\n",
    "    # merge the two images\n",
    "    #print(\"dimension of original is {}\".format(orig_image.shape))\n",
    "    #print(\"dimension of bg_image_warped_back is {}\".format(orig_image.shape))\n",
    "    orig_image = blend_transparent(orig_image, bg_image_warped_back)\n",
    "    if not video_mode:\n",
    "        plt.imshow(orig_image)\n",
    "        plt.title(\"enhanced bird eye warped back merged with original\")\n",
    "        plt.show()\n",
    "\n",
    "    # write text\n",
    "    assembled_image = orig_image.copy()\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(assembled_image, \"Radius left line: {0:.2f}m\".format(left_r), (50, 50), font, 1, (255, 255, 255), 2,\n",
    "                cv2.LINE_AA)\n",
    "    cv2.putText(assembled_image, \"Radius right line: {0:.2f}m\".format(right_r), (50, 80), font, 1, (255, 255, 255), 2,\n",
    "                cv2.LINE_AA)\n",
    "    cv2.putText(assembled_image, \"Vehicle position: {0:.2f}m {1} of center\".format(dx, ('left' if dx > 0 else 'right'))\n",
    "                , (50, 110), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(assembled_image, \"Left line detected: {} (trust={})\".format(('yes' if left_line.detected else 'no'), \n",
    "                                                                            len(left_line.allx))\n",
    "            , (50, 140), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(assembled_image, \"Right line detected: {} (trust={})\".format(('yes' if right_line.detected else 'no'),\n",
    "                                                                            len(right_line.allx))\n",
    "        , (50, 170), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    #cv2.putText(assembled_image, \"{0:.3}, {1:.3}, {2:.3} / {3:.3}, {4:.3}, {5:.3}\".format(left_fit_cr_avg[0],left_fit_cr_avg[1],\n",
    "    #                                                     left_fit_cr_avg[2],\n",
    "    #                                                     right_fit_cr_avg[0],\n",
    "    #                                                     right_fit_cr_avg[1],\n",
    "    #                                                     right_fit_cr_avg[2],)\n",
    "    #    , (50, 200), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    if not video_mode:\n",
    "        plt.imshow(assembled_image)\n",
    "        plt.show()\n",
    "\n",
    "    return assembled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitize_lane_pixels(max_y=680):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    idx = left_line.ally < max_y\n",
    "    left_line.ally = left_line.ally[idx]\n",
    "    left_line.allx = left_line.allx[idx]\n",
    "    \n",
    "    idx = right_line.ally < max_y\n",
    "    right_line.ally = right_line.ally[idx]\n",
    "    right_line.allx = right_line.allx[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def get_lane_pixels_wo_sliding_window(binary_warped, video_mode=False, max_y = 650):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    sanitize_lane_pixels()\n",
    "    \n",
    "    left_fit=left_line.get_averaged_fit()\n",
    "    right_fit=right_line.get_averaged_fit()\n",
    "    \n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # sanitize\n",
    "    idx = nonzeroy < max_y\n",
    "    nonzeroy = nonzeroy[idx]\n",
    "    nonzerox = nonzerox[idx]\n",
    "    \n",
    "    margin = 150\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "    left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "    right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    if len(lefty) > 3:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        # assign to global object\n",
    "        left_line.allx = leftx\n",
    "        left_line.ally = lefty\n",
    "        left_line.detected = True\n",
    "    else:\n",
    "        left_line.detected = False\n",
    "\n",
    "    if len(righty) > 3:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        right_line.allx = rightx\n",
    "        right_line.ally = righty    \n",
    "        right_line.detected = True\n",
    "    else:\n",
    "        right_line.detected = False\n",
    "        \n",
    "    left_line.trust = len(lefty)\n",
    "    right_line.trust = len(righty)\n",
    "\n",
    "    if not video_mode:  #visualize\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                      ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                      ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.figure()\n",
    "        plt.imshow(result)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        plt.title(\"lines without sliding window\")\n",
    "        #plt.show()\n",
    "        millis = int(round(time.time() * 1000))\n",
    "        plt.savefig('debug/debug' + str(millis) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_lane_pixels(binary_warped, window_height = 80):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high), (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high), (0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    return leftx, lefty, rightx, righty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lane_pixels_from_centroids(window_centroids, binary_warped, window_width = 50, window_height = 80, video_mode=False):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    sanitize_lane_pixels()\n",
    "    \n",
    "    # If we found any window centers\n",
    "    if len(window_centroids) > 0:\n",
    "\n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(binary_warped)\n",
    "        r_points = np.zeros_like(binary_warped)\n",
    "\n",
    "        # Go through each level and draw the windows\n",
    "        for level in range(0,len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            l_mask = window_mask(window_width,window_height,binary_warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,binary_warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage = np.array(cv2.merge((binary_warped,binary_warped,binary_warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "\n",
    "        if not video_mode:\n",
    "            # Display the final results\n",
    "            plt.figure()\n",
    "            plt.imshow(output)\n",
    "            plt.title('window fitting results')\n",
    "            plt.show(block=False)\n",
    "            \n",
    "        l_nonzero = cv2.bitwise_and(binary_warped, l_points) # l_nonzero is an image holding only pixels from the left line\n",
    "        if not video_mode:\n",
    "            plt.imshow(l_nonzero, cmap=\"gray\")\n",
    "            plt.title('left lane pixels that align with fitted windows')\n",
    "            plt.show()\n",
    "        lefty = np.array(l_nonzero.nonzero()[0])\n",
    "        leftx = np.array(l_nonzero.nonzero()[1])\n",
    "        r_nonzero = cv2.bitwise_and(binary_warped, r_points)\n",
    "        if not video_mode:\n",
    "            plt.imshow(r_nonzero, cmap=\"gray\")\n",
    "            plt.title('right lane pixels that align with fitted windows')\n",
    "            plt.show()\n",
    "        righty = np.array(r_nonzero.nonzero()[0])\n",
    "        rightx = np.array(r_nonzero.nonzero()[1])\n",
    "        \n",
    "        # if no lane was detected, just add the pixels to the array\n",
    "        if not left_line.detected:\n",
    "            print(leftx)\n",
    "            left_line.allx = np.concatenate((left_line.allx, leftx))\n",
    "            left_line.ally = np.concatenate((left_line.ally, lefty))\n",
    "        else:\n",
    "            left_line.allx = leftx\n",
    "            left_line.ally = lefty\n",
    "            \n",
    "        # if no lane was detected, just add the pixels to the array\n",
    "        if not right_line.detected:\n",
    "            right_line.allx = np.concatenate((right_line.allx, rightx))\n",
    "            right_line.ally = np.concatenate((right_line.ally, righty))\n",
    "        else:\n",
    "            right_line.allx = rightx\n",
    "            right_line.ally = righty\n",
    "        \n",
    "        return lefty, leftx, righty, rightx\n",
    "    else:\n",
    "        # If no window centers found, just display orginal road image\n",
    "        log(\"no window center found...\")\n",
    "        output = np.array(cv2.merge((warped)),np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_position_metrics_and_paint(ploty, image_width, warped, orig,\n",
    "                                   video_mode, use_weights=True):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    lefty = left_line.ally[::-1]\n",
    "    leftx = left_line.allx[::-1]\n",
    "    righty = right_line.ally[::-1]\n",
    "    rightx = right_line.allx[::-1]\n",
    "        \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/638 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space    \n",
    "    # enhancement: trust close pixels more\n",
    "    # the more distant (smaller y), the less weight\n",
    "    # the closer to the edge (left: smaller x, right bigger x) the less weight\n",
    "    base_trust = -0.5\n",
    "\n",
    "    if use_weights:\n",
    "        left_weights = lefty / np.max(lefty) + leftx / np.max(leftx) + base_trust\n",
    "        right_weights = righty / np.max(righty) + (np.max(rightx) - rightx) / np.max(rightx) + base_trust\n",
    "    else:\n",
    "        left_weights = np.ones(len(lefty))\n",
    "        right_weights = np.ones(len(righty))\n",
    "    left_fit = np.polyfit(lefty, leftx, 2, w=left_weights)\n",
    "    right_fit = np.polyfit(righty, rightx, 2, w=right_weights)\n",
    "    # add to last fits\n",
    "    left_line.append_fit(left_fit)\n",
    "    right_line.append_fit(right_fit)\n",
    "    \n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2, w=left_weights)  # fit real world and get curvature\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2, w=right_weights)    \n",
    "    left_r_meters = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_r_meters = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    left_line.radius_of_curvature = left_r_meters\n",
    "    right_line.radius_of_curvature = right_r_meters\n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    if not video_mode: print(\"{0:.1f}m, {1:.1f}m\".format(left_r_meters, right_r_meters))\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    # first, get pixels close to car\n",
    "    close_r_x = rightx[righty>500]\n",
    "    close_l_x = leftx[lefty>500]\n",
    "    left_lane_center_px = np.mean(close_l_x)\n",
    "    right_lane_center_px = np.mean(close_r_x)\n",
    "    \n",
    "    deviation_from_middle_pixel = (image_width / 2) - (right_lane_center_px+left_lane_center_px) / 2 \n",
    "    deviation_from_middle_meter = deviation_from_middle_pixel * xm_per_pix\n",
    "    if deviation_from_middle_meter != deviation_from_middle_meter:\n",
    "        # is NaN\n",
    "        deviation_from_middle_meter = 0\n",
    "\n",
    "    assembled_image = fit_lanes_on_image(leftx, lefty, rightx, righty,  \n",
    "                                          dx=deviation_from_middle_meter, \n",
    "                                          right_r=right_r_meters, left_r=left_r_meters,\n",
    "                                          birdeye_image=warped, orig_image=orig,\n",
    "                                          ploty = ploty, video_mode=video_mode)\n",
    "    \n",
    "    return assembled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def work_image(binary_warped, warped_img, orig_img, video_mode):\n",
    "    global first_frame\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    ww = 70\n",
    "    wh = 160\n",
    "    if first_frame:\n",
    "        window_centroids = find_window_centroids(binary_warped, window_width = ww , window_height = wh, margin = 80,\n",
    "                                                 video_mode=video_mode)\n",
    "        get_lane_pixels_from_centroids(window_centroids, \n",
    "                                       binary_warped, window_width = ww, window_height = wh,\n",
    "                                       video_mode=video_mode)\n",
    "        first_frame = False\n",
    "    else:\n",
    "        get_lane_pixels_wo_sliding_window(binary_warped, video_mode=video_mode)\n",
    "        \n",
    "    #leftx, lefty, rightx, righty = get_lane_pixels(binary_warped) # alternative\n",
    "    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    assembled_image = get_position_metrics_and_paint(ploty, image_width=img.shape[1],\n",
    "                                                     warped=warped_img, orig=orig_img,\n",
    "                                                     video_mode=video_mode)\n",
    "\n",
    "    return assembled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "first_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_image(img, video_mode = False):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    if not video_mode:\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"original image\")\n",
    "        plt.show()\n",
    "\n",
    "    undistorted = ud(img)\n",
    "    if not video_mode:\n",
    "        plt.imshow(undistorted)\n",
    "        plt.title(\"undistorted image\")\n",
    "        plt.show()\n",
    "\n",
    "    warped = warp(undistorted)\n",
    "    if not video_mode:\n",
    "        plt.imshow(warped, cmap=\"gray\")\n",
    "        plt.title(\"warped to bird eye\")\n",
    "        plt.show()\n",
    "\n",
    "    # orig s_thresh=(170, 255), sx_thresh=(20, 100))\n",
    "    binary_warped = threshold(warped, s_thresh=(170, 255), sx_thresh=(20, 200))\n",
    "    if not video_mode:\n",
    "        plt.imshow(binary_warped, cmap=\"gray\")\n",
    "        plt.title(\"binarized using light channel and sobel X operator\")\n",
    "        plt.show()\n",
    "\n",
    "    assembled_image = work_image(binary_warped, warped, undistorted, video_mode)\n",
    "    if not video_mode:\n",
    "        plt.imshow(assembled_image)\n",
    "        plt.title(\"final image\")\n",
    "        plt.show()\n",
    "        \n",
    "    return assembled_image\n",
    "\n",
    "#img = mpimg.imread(\"stress_images/vlcsnap-2017-09-29-09h04m55s971.png\")\n",
    "#img = mpimg.imread(\"test_images/straight_lines1.jpg\")\n",
    "img = mpimg.imread(\"test_images/test4.jpg\")\n",
    "ai = process_image(img, video_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete pipeline, executed a single time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "first_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def prcs(img):\n",
    "    return process_image(img, video_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "read_input = \"project_video.mp4\"\n",
    "white_output = 'output/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(read_input)\n",
    "white_clip = clip1.fl_image(prcs) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
